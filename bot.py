import os
import asyncio
import logging
import httpx
from datetime import datetime
from bs4 import BeautifulSoup
from aiohttp import web
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import CommandStart
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.webhook.aiohttp_server import SimpleRequestHandler
from aiogram.exceptions import TelegramBadRequest

# ================== CONFIG & LOGGING ==================
BOT_TOKEN = os.getenv("BOT_TOKEN")
WEBHOOK_HOST = os.getenv("WEBHOOK_HOST")
PORT = int(os.getenv("PORT", 8080))

if not BOT_TOKEN or not WEBHOOK_HOST:
    raise RuntimeError("BOT_TOKEN –∞–±–æ WEBHOOK_HOST –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")

WEBHOOK_PATH = "/webhook"
WEBHOOK_URL = f"{WEBHOOK_HOST}{WEBHOOK_PATH}"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
log = logging.getLogger(__name__)

bot = Bot(token=BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()

# ================== SOURCES & BASE URLS ==================
SOURCES = {
    "hamster": "https://hamster-combo.com",
    "tapswap": "https://miningcombo.com/tapswap-2/",
    "blum": "https://miningcombo.com/blum-2/",
    "cattea": "https://miningcombo.com/cattea/",
    "tonstation": "https://miningcombo.com/ton-station/",
}

BASE_URLS = {
    "hamster": "https://hamster-combo.com",
    "tapswap": "https://miningcombo.com",
    "blum": "https://miningcombo.com",
    "cattea": "https://miningcombo.com",
    "tonstation": "https://miningcombo.com",
}

# ================== –î–û–ü–û–ú–Ü–ñ–ù–ê –§–£–ù–ö–¶–Ü–Ø –î–õ–Ø –ó–û–ë–†–ê–ñ–ï–ù–¨ (–û–ù–û–í–õ–ï–ù–û) ==================
def _find_combo_image_url(soup: BeautifulSoup, game_name: str, base_url: str) -> str | None:
    """–®—É–∫–∞—î —Ç–µ–≥ <img> –∑ –∫–ª—é—á–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ –£–°–ï–†–ï–î–ò–ù–Ü –ö–û–ù–¢–ï–ù–¢–£ —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î –∞–±—Å–æ–ª—é—Ç–Ω–∏–π URL."""
    
    # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞, —è–∫—ñ –≤–∫–∞–∑—É—é—Ç—å –Ω–∞ –∫–æ–º–±–æ
    keywords = ["combo", "cipher", "–∫–æ–º–±–æ", "daily", "—â–æ–¥–µ–Ω–Ω–µ", game_name.lower().replace(" ", "-")]
    # –°–ª–æ–≤–∞, —è–∫—ñ –≤–∫–∞–∑—É—é—Ç—å –Ω–∞ –ª–æ–≥–æ—Ç–∏–ø, —ñ–∫–æ–Ω–∫—É —á–∏ –∑–∞–≥–ª—É—à–∫—É
    EXCLUDED_KEYWORDS = ["logo", "icon", "favicon", "cropped", "placeholder", "74x95", "150x150"] 
    
    content_area = soup.find(["article", "div"], class_=lambda x: x and ('entry-content' in x or 'main-content' in x or 'post-content' in x))
    if not content_area:
        content_area = soup

    for img in content_area.find_all("img"):
        src = img.get("src", "")
        alt = img.get("alt", "")
        title = img.get("title", "")
        
        img_check_string = src.lower() + alt.lower() + title.lower()
        
        # 1. –í–∏–∫–ª—é—á–∞—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–∞ –∫–ª—é—á–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
        if any(exc in img_check_string for exc in EXCLUDED_KEYWORDS):
            continue

        # 2. –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –º–∞—î –±—É—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏–º –ê–ë–û –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –≤–µ–ª–∏–∫–∏–º
        is_relevant = any(k in img_check_string for k in keywords)
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä–æ–∑–º—ñ—Ä—É (—Ñ—ñ–ª—å—Ç—Ä –º–∞–ª–∏—Ö –∫–∞—Ä—Ç–∏–Ω–æ–∫)
        is_large_enough = False
        width = img.get("width")
        height = img.get("height")
        try:
            if width and height and int(width) > 100 and int(height) > 100:
                is_large_enough = True
        except ValueError:
            pass

        if is_relevant or is_large_enough:
            # –í–∏—Ä—ñ—à–µ–Ω–Ω—è –≤—ñ–¥–Ω–æ—Å–Ω–æ–≥–æ —à–ª—è—Ö—É
            if src.startswith('http'):
                return src
            elif src.startswith('//'):
                return f"https:{src}"
            elif src.startswith('/'):
                return base_url.rstrip('/') + src
            
    return None

# ================== –ü–ê–†–°–ï–†–ò (–ó –î–û–î–ê–¢–ö–û–í–ò–ú –ê–†–ì–£–ú–ï–ù–¢–û–ú) ==================

# –¢–µ–ø–µ—Ä –ø–∞—Ä—Å–µ—Ä–∏ –ø—Ä–∏–π–º–∞—é—Ç—å `prefer_text: bool`
def parse_hamster(html: str, prefer_text: bool = False) -> str:
    soup = BeautifulSoup(html, "html.parser")
    base_url = BASE_URLS["hamster"]

    # 1. –°–ø—Ä–æ–±–∞ –∑–Ω–∞–π—Ç–∏ –ó–û–ë–†–ê–ñ–ï–ù–ù–Ø (—è–∫—â–æ prefer_text=False)
    if not prefer_text:
        image_url = _find_combo_image_url(soup, "hamster", base_url)
        if image_url:
            return f"__IMAGE_URL__:{image_url}"

    # 2. –¢–ï–ö–°–¢–û–í–ò–ô FALLBACK
    header = soup.find(lambda tag: tag.name in ["h1", "h2", "h3", "h4"] and "combo" in tag.get_text(strip=True).lower())
    if not header:
        return "‚è≥ <b>–ö–æ–º–±–æ —â–µ –Ω–µ –æ–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–µ</b>"
    cards = []
    # –ü–æ—á–∏–Ω–∞—î–º–æ –ø–æ—à—É–∫ —Ç–µ–∫—Å—Ç—É –æ–¥—Ä–∞–∑—É –ø—ñ—Å–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
    for tag in header.find_all_next(["p", "li", "div", "span", "strong"]):
        text = tag.get_text(strip=True)
        if text.isupper() and 4 <= len(text) <= 30 and text not in cards and "combo" not in text.lower():
            cards.append(text)
        if len(cards) >= 3:
            break
    if len(cards) < 3:
        return "‚è≥ <b>–ö–æ–º–±–æ —â–µ –Ω–µ –æ–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–µ</b>"
    return "\n".join(f"‚Ä¢ <b>{c}</b>" for c in cards[:3])

def parse_tapswap(html: str, prefer_text: bool = False) -> str:
    soup = BeautifulSoup(html, "html.parser")
    base_url = BASE_URLS["tapswap"]
    
    if not prefer_text:
        image_url = _find_combo_image_url(soup, "tapswap", base_url)
        if image_url:
            return f"__IMAGE_URL__:{image_url}"
        
    codes = []
    for tag in soup.find_all(["p", "div", "span", "strong"]):
        text = tag.get_text(strip=True)
        if "code" in text.lower() or "cipher" in text.lower():
            parts = text.split()
            for part in parts:
                cleaned_part = ''.join(filter(str.isalnum, part))
                if cleaned_part.isalnum() and 4 <= len(cleaned_part) <= 10:
                    codes.append(cleaned_part.upper())
    codes = list(dict.fromkeys(codes))
    return "\n".join(f"‚Ä¢ <b>{c}</b>" for c in codes[:5]) or "‚è≥ <b>–ö–æ–º–±–æ —â–µ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ</b>"

def parse_blum(html: str, prefer_text: bool = False) -> str:
    soup = BeautifulSoup(html, "html.parser")
    base_url = BASE_URLS["blum"]
    
    if not prefer_text:
        image_url = _find_combo_image_url(soup, "blum", base_url)
        if image_url:
            return f"__IMAGE_URL__:{image_url}"
        
    codes = []
    for tag in soup.find_all(["strong", "p", "span", "div"]):
        text = tag.get_text(strip=True)
        if text.isupper() and 5 <= len(text) <= 20 and text not in codes and "combo" not in text.lower():
            codes.append(text)
        if len(codes) >= 3:
            break
    return "\n".join(f"‚Ä¢ <b>{c}</b>" for c in codes[:3]) or "‚è≥ <b>–ö–æ–º–±–æ —â–µ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ</b>"

def parse_cattea(html: str, prefer_text: bool = False) -> str:
    soup = BeautifulSoup(html, "html.parser")
    base_url = BASE_URLS["cattea"]
    
    if not prefer_text:
        image_url = _find_combo_image_url(soup, "cattea", base_url)
        if image_url:
            return f"__IMAGE_URL__:{image_url}"
        
    if "searching" in html.lower() or "coming soon" in html.lower():
        return "‚è≥ <b>–ö–æ–º–±–æ —â–µ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ (searching...)</b>"
    
    header = soup.find(lambda tag: tag.name in ["h2", "h3", "h4"] and "cattea" in tag.get_text(strip=True).lower())
    if not header:
        return "‚è≥ <b>–ö–æ–º–±–æ —â–µ –Ω–µ –æ–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–µ</b>"
    cards = []
    for tag in header.find_all_next(["p", "li", "div", "strong", "span"]):
        text = tag.get_text(strip=True)
        if text and len(text) > 3 and text not in cards and "combo" not in text.lower():
            cards.append(text)
        if len(cards) >= 4:
            break
    return "\n".join(f"‚Ä¢ <b>{c}</b>" for c in cards[:4]) or "‚è≥ <b>–ö–æ–º–±–æ —â–µ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ</b>"

def parse_tonstation(html: str, prefer_text: bool = False) -> str:
    soup = BeautifulSoup(html, "html.parser")
    base_url = BASE_URLS["tonstation"]

    if not prefer_text:
        image_url = _find_combo_image_url(soup, "ton station", base_url)
        if image_url:
            return f"__IMAGE_URL__:{image_url}"

    if "searching" in html.lower():
        return "‚è≥ <b>–ö–æ–º–±–æ —â–µ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ (searching...)</b>"
    
    header = soup.find(lambda tag: tag.name in ["h2", "h3"] and "ton station" in tag.get_text(strip=True).lower())
    if not header:
        return "‚è≥ <b>–ö–æ–º–±–æ —â–µ –Ω–µ –æ–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–µ</b>"
    cards = []
    for tag in header.find_all_next(["p", "li", "div"]):
        text = tag.get_text(strip=True)
        if text and len(text) > 3 and text not in cards and "combo" not in text.lower():
            cards.append(text)
        if len(cards) >= 4:
            break
    return "\n".join(f"‚Ä¢ <b>{c}</b>" for c in cards[:4]) or "‚è≥ <b>–ö–æ–º–±–æ —â–µ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ</b>"

# ================== FETCH ==================
async def fetch(url: str) -> str:
    async with httpx.AsyncClient(timeout=20) as c:
        log.info(f"HTTP Request: GET {url}")
        r = await c.get(url, follow_redirects=True)
        r.raise_for_status()
        return r.text

# ================== UI ==================
def main_kb():
    return types.InlineKeyboardMarkup(inline_keyboard=[
        [
            types.InlineKeyboardButton(text="üêπ Hamster", callback_data="hamster"),
            types.InlineKeyboardButton(text="‚ö° TapSwap", callback_data="tapswap")
        ],
        [
            types.InlineKeyboardButton(text="üå∏ Blum", callback_data="blum"),
            types.InlineKeyboardButton(text="üê± CatTea", callback_data="cattea")
        ],
        [types.InlineKeyboardButton(text="üöâ TON Station", callback_data="tonstation")]
    ])

def back_kb():
    return types.InlineKeyboardMarkup(inline_keyboard=[
        [types.InlineKeyboardButton(text="<< –ù–∞–∑–∞–¥ –¥–æ –º–µ–Ω—é", callback_data="back_to_menu")]
    ])

# ================== HANDLERS (–ö–õ–Æ–ß–û–í–ï –û–ù–û–í–õ–ï–ù–ù–Ø) ==================

@dp.message(CommandStart())
async def start(m: types.Message):
    await m.answer("<b>üéÆ –©–æ–¥–µ–Ω–Ω—ñ –∫–æ–º–±–æ —ñ–≥–æ—Ä</b>\n\n–û–±–µ—Ä–∏ –≥—Ä—É:", reply_markup=main_kb())

@dp.callback_query(F.data.in_(SOURCES.keys()))
async def send_combo(cb: types.CallbackQuery):
    # –ü–æ—á–∞—Ç–∫–æ–≤–∏–π —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä
    await cb.message.edit_text("‚è≥ –û—Ç—Ä–∏–º—É—é –¥–∞–Ω—ñ...", reply_markup=main_kb()) 
    
    game = cb.data
    name = {
        "hamster": "üêπ Hamster Kombat",
        "tapswap": "‚ö° TapSwap",
        "blum": "üå∏ Blum",
        "cattea": "üê± CatTea",
        "tonstation": "üöâ TON Station"
    }[game]

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ñ—É–Ω–∫—Ü—ñ—é –ø–∞—Ä—Å–µ—Ä–∞
    parser_map = {
        "hamster": parse_hamster,
        "tapswap": parse_tapswap,
        "blum": parse_blum,
        "cattea": parse_cattea,
        "tonstation": parse_tonstation,
    }
    parser_func = parser_map[game]
    
    try:
        html = await fetch(SOURCES[game])

        # –°–ø—Ä–æ–±–∞ 1: –ü–∞—Ä—Å–∏–Ω–≥ —ñ–∑ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º
        combo_result = parser_func(html, prefer_text=False)
        is_image_attempt = False
        
        if combo_result.startswith("__IMAGE_URL__:") and len(combo_result) > 14:
            image_url = combo_result[14:]
            is_image_attempt = True
            
            log.info(f"Attempting to send image for {game} from URL: {image_url}")

            # –ù–∞–¥—ñ—Å–ª–∞—Ç–∏ –ó–û–ë–†–ê–ñ–ï–ù–ù–Ø
            caption = f"<b>{name}</b>\n–ö–æ–º–±–æ –Ω–∞ <b>{datetime.now():%d.%m.%Y}</b>\n\n‚úÖ <b>–ö–æ–º–±–æ –∑–Ω–∞–π–¥–µ–Ω–æ —è–∫ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.</b>"
            
            try:
                await bot.send_photo(
                    chat_id=cb.message.chat.id,
                    photo=image_url,
                    caption=caption,
                    reply_markup=back_kb(),
                    parse_mode=ParseMode.HTML
                )
                # –Ø–∫—â–æ —É—Å–ø—ñ—à–Ω–æ, –≤–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä–∏–π —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä
                await cb.message.delete()
                return # –£—Å–ø—ñ—Ö, –≤–∏—Ö–æ–¥–∏–º–æ
                
            except TelegramBadRequest as e:
                # –û–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–æ–∫ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å (failed to get HTTP URL content, wrong type)
                if "failed to get HTTP URL content" in str(e) or "wrong type of the web page content" in str(e):
                    log.warning(f"Image send failed for {game} ({image_url}). Reason: {e}. Falling back to text.")
                    # –°–∫–∏–¥–∞—î–º–æ –ø—Ä–∞–ø–æ—Ä is_image_attempt, —â–æ–± –ø–µ—Ä–µ–π—Ç–∏ –¥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É
                    is_image_attempt = False
                    
                else:
                    # –Ü–Ω—à–∞ –Ω–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ Telegram, –≤–∏–≤–æ–¥–∏–º–æ —ó—ó –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–≤—ñ
                    raise e 
        
        # –°–ø—Ä–æ–±–∞ 2: –ü–∞—Ä—Å–∏–Ω–≥ –ª–∏—à–µ —Ç–µ–∫—Å—Ç—É, —è–∫—â–æ —Å–ø—Ä–æ–±–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—è –∞–±–æ –Ω–µ –±—É–ª–æ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        if not is_image_attempt:
            # –ü–∞—Ä—Å–∏–º–æ –ª–∏—à–µ —Ç–µ–∫—Å—Ç, —ñ–≥–Ω–æ—Ä—É—é—á–∏ –ø–æ—à—É–∫ –∑–æ–±—Ä–∞–∂–µ–Ω—å
            combo_result = parser_func(html, prefer_text=True)
            text = f"<b>{name}</b>\n–ö–æ–º–±–æ –Ω–∞ <b>{datetime.now():%d.%m.%Y}</b>\n\n{combo_result}"
            await cb.message.edit_text(text, reply_markup=back_kb())


    except Exception as e:
        log.error(f"Critical Error for {game}: {e}")
        text = f"‚ùå <b>–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –¥–ª—è {name}</b>\n–°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ. –î–µ—Ç–∞–ª—ñ: {type(e).__name__}"
        try:
            await cb.message.edit_text(text, reply_markup=back_kb())
        except:
            await cb.message.answer(text, reply_markup=back_kb())

@dp.callback_query(F.data == "back_to_menu")
async def back_to_menu_handler(cb: types.CallbackQuery):
    await cb.answer()
    menu_text = "<b>üéÆ –©–æ–¥–µ–Ω–Ω—ñ –∫–æ–º–±–æ —ñ–≥–æ—Ä</b>\n\n–û–±–µ—Ä–∏ –≥—Ä—É:"
    try:
        # 1. –°–ø—Ä–æ–±–∞ –≤—ñ–¥—Ä–µ–¥–∞–≥—É–≤–∞—Ç–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è (–ø—Ä–∞—Ü—é—î –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å)
        await cb.message.edit_text(menu_text, reply_markup=main_kb())
    except Exception as e:
        log.warning(f"Failed to edit message back to menu: {e}. Sending new message instead.")
        # 2. –Ø–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥—Ä–µ–¥–∞–≥—É–≤–∞—Ç–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, —Ü–µ –±—É–ª–æ —Ñ–æ—Ç–æ), –Ω–∞–¥—Å–∏–ª–∞—î–º–æ –Ω–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
        await cb.message.answer(menu_text, reply_markup=main_kb())
        try:
             # 3. –í–∏–¥–∞–ª—è—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è, –¥–æ —è–∫–æ–≥–æ –±—É–ª–∞ –ø—Ä–∏–∫—Ä—ñ–ø–ª–µ–Ω–∞ –∫–Ω–æ–ø–∫–∞ "–ù–∞–∑–∞–¥" (—Ç–æ–±—Ç–æ —Ñ–æ—Ç–æ)
             await cb.message.delete()
        except Exception as e:
             log.warning(f"Failed to delete old photo message: {e}")


# ================== WEBHOOK ==================
async def on_startup(app: web.Application):
    await bot.delete_webhook(drop_pending_updates=True)
    await bot.set_webhook(WEBHOOK_URL)
    log.info(f"‚úÖ Webhook –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {WEBHOOK_URL}")

app = web.Application()
app.on_startup.append(on_startup)
SimpleRequestHandler(dispatcher=dp, bot=bot).register(app, path=WEBHOOK_PATH)

if __name__ == "__main__":
    log.info(f"–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ 0.0.0.0:{PORT}")
    web.run_app(app, host="0.0.0.0", port=PORT)
